:sectnums:
:sectanchors:
:PORTDB_URL: the full JDBC connection string used to connect to the Entando PORT database
:PORTDB_DATABASE: the name of the Entando PORT database that is created and hosted in the image
:PORTDB_JNDI: the full JNDI name where the Entando PORT datasource will be made available to the Entando Engine JEE application
:PORTDB_DRIVER: the name of the driver for the Entando PORT database as configured in the JEE application server
:PORTDB_USERNAME: the username of the user that has read/write access to the Entando PORT database
:PORTDB_PASSWORD: the password of the above-mentioned username.
:PORTDB_SERVICE_HOST: the  name of the server that hosts the Entando PORT database.
:PORTDB_SERVICE_PORT: the port on the above-mentioned server that serves the Entando PORT database. Generally we keep to the default port for each RDBMS, e.g. for PostgreSQL it is 5432
:SERVDB_URL: the full JDBC connection string used to connect to the Entando SERV database
:SERVDB_DATABASE: - the name of the Entando SERV database that is created and hosted in the image
:SERVDB_JNDI: the full JNDI name where the Entando SERV datasource will be made available to the Entando Engine JEE application
:SERVDB_DRIVER: the name of the driver for the Entando SERV database as configured in the JEE application server
:SERVDB_USERNAME: the username of the user that has read/write access to the Entando SERV database. For compatibility with mvn jetty:run, please keep this the same as PORTDB_USERNAME
:SERVDB_PASSWORD: the password of the above-mentioned username.  For compatibility with mvn jetty:run, please keep this the same as PORTDB_PASSWORD
:SERVDB_SERVICE_HOST: the  name of the server that hosts the Entando SERV database
:SERVDB_SERVICE_PORT: the port on the above-mentioned server that serves the Entando SERV database. Generally we keep to the default port for each RDBMS, e.g. for PostgreSQL it is 5432
:ADMIN_USERNAME: the username of a user that has admin rights on both the SERV and PORT databases. For compatibility with Postgresql, keep this value to 'postgres'
:ADMIN_PASSWORD: the password of the above-mentioned username.
:KIE_SERVER_BASE_URL: The base URL where a KIE Server instance is hosted, e.g. http://entando-kieserver701.apps.serv.run/
:KIE_SERVER_USERNAME: The username of a user that be used to log into the above-mentioned KIE Server
:KIE_SERVER_PASSWORD: The password of the above-mentioned KIE Server user.
:ENTANDO_OIDC_ACTIVE: set this variable's value to "true" to activate Entando's Open ID Connect and the related OAuth authentication infrastructure. If set to "false" all the subsequent OIDC  variables will be ignored. Once activated, you may need to log into Entando using the following url: <application_base_url>/<lang_code>/<any_public_page_code>.page?username=<MY_USERNAME>&password=<MY_PASSWORD>
:ENTANDO_OIDC_AUTH_LOCATION: the URL of the authentication service, e.g. the 'login page' that Entando needs to redirect the user to in order to  allow the OAuth provider to authenticate the user.
:ENTANDO_OIDC_TOKEN_LOCATION: the URL of the token service where Entando can retrieve the OAuth token from after authentication
:ENTANDO_OIDC_CLIENT_ID: the Client ID that uniquely identifies the Entando App in the OAuth provider's configuration
:ENTANDO_OIDC_REDIRECT_BASE_URL: the optional base URL, typically the protocol, host and port (https://some.host.com:8080/) that will be prepended to the path segment of the URL requested by the user and provided as a redirect URL to the OAuth provider. If empty, the requested URL will be used as is.
:DOMAIN:  the HTTP URL on which the associated Entando Engine instance will be served
:CLIENT_SECRET: the secret associated with the 'appbuilder' Oauth Client ID in the Entando OAuth infrastructure.
:PORT_5000: the port for the NodeJS HTTP Service on images that serve JavaScript applications
:PORT_8080: the port for the HTTP service hosted by JEE Servleit Containers on images that host Java services
:PORT_8778: the port for the JGroups service on JBoss/Wildfly on images that support JGroups
:PORT_8443: the port for  the HTTPS service hosted by JEE Servlet Containers that support HTTPS. (P.S. generally we prefer to configure HTTPS on a router such as the Openshift Router)

:APP_BUILDER_IMAGE: https://github.com/entando/entando-ops/tree/credit-card-dispute/Docker/Production/entando-full-stack/appbuilder[Entando App Builder Image (entando/appbuilder:latest)]
:ENTANDO_ENGINE_API_IMAGE: https://github.com/entando/entando-ops/tree/credit-card-dispute/Docker/Production/entando-full-stack/entando[The Full Entando Engine API (entando/engine-api:latest)]
:ENTANDO_POSTGRESQL95_BASE_IMAGE: https://github.com/entando/entando-ops/tree/credit-card-dispute/Docker/base-images/entando-postgresql95-base[Entando PostgreSQL 9.5 Base Image (entando/entando-postgresql95-base:latest)]
:ENTANDO_POSTGRESQL95_OPENSHIFT_IMAGE:  https://github.com/entando/entando-ops/tree/credit-card-dispute/Openshift/s2i-images/entando-postgresql95-openshift[Entando PostgreSQL 9.5 Openshift S2I Image (entando/entando-postgresql95-openshift:latest)]
:ENTANDO_EAP71_BASE_IMAGE: https://github.com/entando/entando-ops/tree/credit-card-dispute/Docker/base-images/entando-eap71-base[Entando EAP 7.1 Base Image (entando/entando-eap71-base:latest)]
:ENTANDO_WILDFLY12_BASE_IMAGE: https://github.com/entando/entando-ops/tree/credit-card-dispute/Docker/base-images/entando-wildfly12-base[Entando Wildfly 12 Base Image (entando/entando-wildfly12-base:latest)]
:ENTANDO_EAP71_QUICKSTART_OPENSHIFT_IMAGE: https://github.com/entando/entando-ops/tree/credit-card-dispute/Openshift/s2i-images/entando-eap71-quickstart-openshift[Entando EAP 7.1 Openshift Quickstart Image (entando/entando-eap71-quickstart-openshift:latest)]
:ENTANDO_WILDFLY12_QUICKSTART_OPENSHIFT_IMAGE: https://github.com/entando/entando-ops/tree/credit-card-dispute/Openshift/s2i-images/entando-wildfly12-quickstart-openshift[Entando Wildfly 12 Openshift Quickstart Image (entando/entando-wildfly12-quickstart-openshift:latest)]
:FSI_CC_DISPUTE_CUSTOMER_IMAGE: https://github.com/entando/entando-ops/tree/credit-card-dispute/Docker/demos/fsi-cc-dispute-customer[Entando FSI Credit Card Dispute Customer Image (entando/fsi-cc-dispute-customer:latest)]
:FSI_CC_DISPUTE_ADMIN_IMAGE: https://github.com/entando/entando-ops/tree/credit-card-dispute/Docker/demos/fsi-cc-dispute-admin[Entando FSI Credit Card Dispute Back Office Image (entando/fsi-cc-dispute-admin:latest)]
:ENTANDO_POSTGRESQL_IMAGE: https://github.com/entando/entando-ops/tree/credit-card-dispute/Docker/Production/entando-full-stack/postgresql[PostgreSQL Database Image (entando/postgresql:latest]
:ENTANDO_EAP71_CLUSTERED_BASE_IMAGE: https://github.com/entando/entando-ops/tree/credit-card-dispute/Docker/base-images/entando-eap71-clustered-base[Entando EAP 7.1 Clustered Base Image (entando/entando-eap71-clustered-base:latest)]
:ENTANDO_EAP71_CLUSTERED_OPENSHIFT_IMAGE: https://github.com/entando/entando-ops/tree/credit-card-dispute/Docker/base-images/entando-eap71-clustered-base[Entando EAP 7.1 Clustered Openshift Image (entando/entando-eap71-clustered-openshift:latest)]

:APP_BUILDER_IMAGE_STREAM: Entando AppBuilder Image stream: https://raw.githubusercontent.com/entando/entando-ops/master/Openshift/image-streams/appbuilder.json
:ENTANDO_EAP71_QUICKSTART_OPENSHIFT_IMAGE_STREAM: Entando EAP 7.1 Quickstart Openshift Image Stream: https://raw.githubusercontent.com/entando/entando-ops/master/Openshift/image-streams/entando-eap71-quickstart-openshift.json
:ENTANDO_EAP71_CLUSTERED_OPENSHIFT_IMAGE_STREAM: Entando EAP 7.1 Clustered Openshift Image Stream: https://raw.githubusercontent.com/entando/entando-ops/master/Openshift/image-streams/entando-eap71-clustered-openshift.json
:ENTANDO_POSTGRESQL95_OPENSHIFT_IMAGE_STREAM: Entando PostgreSQL 9.5 Openshift Image Stream: https://raw.githubusercontent.com/entando/entando-ops/master/Openshift/image-streams/entando-postgresql95-openshift.json

:APPLICATION_NAME:  an Openshift compliant name that can be used as a prefix to automatically  generate names for related objects in the Template
:IMAGE_STREAM_NAMESPACE: the name of the Openshift project that contains all the  ImageStreams required for the Template  in question. If the ImageStreams are created the default 'openshift' project,  Openshift will automatically add it to  its application catalog. It is however possible to store them in any   project, including the project that the current Template is being instantiated in.
:IMAGE_STREAM_TAG: the name of a Tag in the ImageStreams that will be used to bind all  S2I BuildConfigs and  DeploymentConfigs to. This generally corresponds with the verion of Entando being used.
:ENTANDO_RUNTIME_HOSTNAME_HTTP: the fully qualified domain name of the Route that will be  created to expose the Entando   Runtime Service. Where there is a Route that supports HTTPS, use the *_HTTPS  variant of this parameter. This variable  is often used to connect to from the App Builder. You therefore need to make sure that it is accessible from outside the Openshift cluster.
:ENTANDO_APP_BUILDER_HOSTNAME_HTTP: the fully qualified domain name of the Route that will be  created to expose the Entando App Builder JavaScript App.
:ENTANDO_BASEURL: The full URL that AppBuilder must use to connect to the Entando Runtime. This parameter is required in situations where AppBuilder can connet to the Entando Runtime using either HTTP or HTTPS. AppBuilder does not work well with self-signed certificates so for test environments you may sometimes fall back on the HTTP Route.
:ENTANDO_WEB_CONTEXT: the context root  of the Entando Web Application. This is the context  on the JEE server that will be used to dispatch requests to the Entando Web Application. Generally this would be the same as the APPLICATION_NAME. In typical JEE deployments this would be the name of the war file, excluding the '.war' extension. In typical Maven projects, this would be the value of the <finalName> element in the pom.xml
:SOURCE_REPOSITORY_URL: the full URL of the source repository where the source code of the image that needs to be built can be found
:SOURCE_REPOSITORY_REF: the branch or tag that will be checked out from the source repository specified at the SOURCE_REPOSITORY_URL
:SOURCE_SECRET: the Openshift Secret containing the Username and Password for the source repository specified at the SOURCE_REPOSITORY_URL
:CONTEXT_DIR: the relative directory inside the source repository from which the build should be  executed.
:VOLUME_CAPACITY: the amount of storage space to be allocated to the Entando App. This needs to be large enough for documents and images that are uploaded, database backups that need to be made,  and the indices that Entando generates. Depending  on the exact template, this may aslo include the space required for the embedded Derby database.
:MEMORY_LIMIT: the maximum amount of memory to be allocated to the Entando JEE App.
:DOMAIN_SUFFIX:  the domain suffix will be appended to the various service names to form a full domain name for the Route of the  mapped to the service. This parameter is required to ensure that the AppBuider points to the externally accessible URL that serves Entando App.
:GITHUB_WEBHOOK_SECRET: Github webhook secret that can be used from Github to trigger builds on this BuildConfig in the Openshift cluster
:GENERIC_WEBHOOK_SECRET: Generic webhook secret that can be used from any generic SCM tool to trigger builds on this BuildConfig in the Openshift cluster
:MAVEN_MIRROR_URL: Maven mirror to use for S2I builds. Specifying a Maven mirror such as Nexus, running in the same cluster can significantly speed up build execution.
:MAVEN_ARGS_APPEND: additional Maven arguments that will be appended to the standard Maven command used in the S2I build
:ARTIFACT_DIR: List of directories from which archives will be copied into the deployment folder. If unspecified, all archives in /target will be copied.


== Overview

Entando currently offers a variety of Docker images that can be used in different container environments, such as
'vanilla' Docker, Openshift or Kubernetes. These images were also developed with different use cases in mind, such as
for simple demos, for getting started with your own app, for more advanced CI/CD, or for production deployments.
Supporting different environments and use cases inevitably comes with some level of complexity. In this chapter,
we will gradually take you from the simpler use cases to the more complex use cases, hopefully easing the learning
curve required for using our Docker images.

== A word on Docker tooling.

While it is theoretically possible to manage this multitude of Entando Docker containers using the 'docker' command, we
strongly recommend using container management tools that allow you to manage multiple containers in concert. Entando
itself is typically deployed on Docker in sets of two to three images. As containerization gains more traction in the
industry, we expect more Entando Docker images to be added to these deployments. We therefor advise even the die-hard
'docker' command line users to familiarize themselves with one or more  container management tool that allows you to easily
deploy, start and stop multiple containers collectively using a single command.

Entando supports Docker Compose and Openshift, both of which simplify the management of multiple Docker containers and setting
up connectivity amongst them. Since Entando Apps are still Java projects built with Maven, we have also added support
for the Fabric8 Maven Docker Plugin for multiple Entando Docker images to be built built and tested during the development and
build processes. We have developed quick starts for all three these technologies to make it easier for new users to
get Entando up and running on Docker.

[[getting-started]]
== Getting Started

You can get started on Entando using either Docker Compose, the Maven Docker Plugin or Openshift. In order to choose the
option that fits your needs the best, consider the following:

* *Docker Compose:* For 'vanilla' Docker installations, the Docker Compose tool allows you to run
several of our images together by using one of the Docker Compose 'YAML' files that we offer. If you have some skill
in Docker, but you have limited interest or skills in development, this would be best way for you to get started.
You can deploy and run a selection of our pre-built, deployment-ready images as configured in our
https://github.com/entando/entando-ops/tree/credit-card-dispute/Docker/Production/entando-full-stack[Docker Compose 'YAML' files].
Get started with <<getting-started-with-docker-compose>>
*  *Maven with Docker:* If you have some development skills, especially around the use of Maven, but
Docker is not necessarily (yet) your forte, this approach may be the best for you. We have a
https://github.com/entando/entando-archetypes/tree/v5.0.2/web-app-bpm-docker/web-app-bpm-docker/src/main/resources/archetype-resources[Maven Archetype]
specifically developed to help you build your project image and run the resulting image in Docker.
<<maven-docker-quickstart>>
* *Openshift:* If you have an Openshift environment at your disposal and you know how to deploy an
Openshift template, the Openshift approach would be best. Openshift doesn't require extensive
knowledge of either the Development world or the Ops world to get started, but it does reward your knowledge of either.
If DevOps is your thing, this approach is ideal for you, and you can choose from our selection of
https://github.com/entando/entando-ops/tree/credit-card-dispute/Openshift/templates[Openshift Templates] to match
your use case. Get started with an <<openshift-quickstart>>

[[getting-started-with-docker-compose]]
=== Docker Compose in a 'vanilla' Docker environment

.Prerequisites:
. You have installed Docker locally.
. You are either running a Linux distribution or MacOS. (Windows still to be tested)
. The https://docs.docker.com/compose/install/[docker-compose command line tool] has also been installed. Some Docker distributions may require you to install this separately.

.Steps:
. Download the Entando Full Stack docker-compose 'YAML' file from https://github.com/entando/entando-ops/tree/credit-card-dispute/Docker/Production/entando-full-stack/docker-compose.yml[Github]
. Open a terminal window and change the present working directory to the directory that you have downloaded the yaml file to.
. It is highly recommended that you first pull the required images from Docker Hub running the command `docker-compose pull`
. Run the command `docker-compose up` to spin up the required Docker containers
. Open your browser and point it to http://localhost:5000. This will open the AppBuilder. Note that on Apple or Windows you won't be using 'localhost' but rather the IP address of the Docker virtual machine.
. Use the credentials admin/adminadmin to log in. Consult our documentation for more details on how to build an Entando App from AppBuilder
. To open the resulting web app, point your browser to http://localhost:8080/entando.  (Remember to replace 'localhost' with the IP address of the Docker virtual machine on Windows and Apple)

.Next steps

Now that you got started on Entando in your Docker platform, you have a couple of different options on how to proceed.
You can have a look at our <<demos-on-docker>> section to see some more demos that you can deploy to Docker. If you are
serious about getting your images deployed to production, we would recommend working through the <<openshift-quickstart>>
section, as Openshift is currently our recommended approach.

[[maven-docker-quickstart]]
=== Getting started on Maven and Docker

.Prerequisites:
. You have installed Docker locally.
. You have installed Java and Maven locally.
. You are either running a Linux distribution or MacOS. (Windows still to be tested)
. It is highly recommended that you have pulled the required images into your Docker environment
using the https://github.com/entando/entando-ops/blob/master/Docker/base-images/pull-quickstart-images.sh[pull-quickstart-images.sh script]

.Steps:
. Open a terminal to the directory you want to place your Maven project in.
. Run:

        mvn archetype:generate -DgroupId=org.entando -DartifactId=entando-docker && \
          -DarchetypeGroupId=org.entando.entando && \
          -DarchetypeArtifactId=entando-archetype-webapp-bpm-docker && \
          -DarchetypeVersion=5.0.2 && \
          -DinteractiveMode=false

. Change the present working directory to the folder of the newly generated project, `entando-docker`
. Run:

        mvn clean install -Pdocker docker:start -DskipAppBuilderImage=false

. Open your browser and point it to http://localhost:5000. This will open the AppBuilder. (On Windows and Apple replace 'localhost' with the IP address of the Docker virtual machine)
. Use the credentials admin/adminadmin to log in. Consult our documentation for more details on how to build an Entando App from AppBuilder
. To open the resulting web app, point your browser to http://localhost:8080/entando. (Remember to replace 'localhost' with the IP address of the Docker virtual machine on Windows and Apple)


.Next steps

Now that you got started on Entando using Maven and the Docker platform, you may want to
consider managing the database yourself, or find out how to use a different base image.
For guidance on how to do this, please consult our <<maven-and-docker>> section
on the use of Docker with our Maven archetypes. If you are serious about getting
your images deployed to production, we would recommend working through the <<openshift-quickstart>>
section, as Openshift is currently our recommended approach.


[[openshift-quickstart]]
===  Openshift Quick Start

.Prerequistes:
. You have access to a fully operational Openshift cluster (could also be a local Minishift installation).
. You have credentials to log into this environment.
. Your user has access to the project named 'openshift'
. It is highly recommended that you or your system admin has pulled all the required images into your Docker environment
using the https://github.com/entando/entando-ops/blob/master/Openshift/installers/pull-quickstart-images.sh[pull-quickstart-images.sh script]
. If you require RedHat Process Automation Manager, we recommend deploying the
https://access.redhat.com/documentation/en-us/red_hat_process_automation_manager/7.0/html-single/deploying_a_red_hat_process_automation_manager_7.0_authoring_environment_on_red_hat_openshift_container_platform/index[Authoring environment template]
 to Openshift and take down the connection details (baseUrl, username and password) of the KIE Server.

There are two different approaches you can follow to deploy Entando to your Openshift environment:

. Using the browser based console. This approach is ideal if you are new to Openshift, if you are not comfortable with the commandline terminal and
if you won't be expected to automate deployment and confguration any time soon.
. Using the `oc` command line interface. This approach is intended for the more low level technical audience, especially if you will be expected
to automate deployment and configuration.

.Steps using the browser based console:
. Log into the browser based console using your credentials.
. Navigate to the 'openshift' project
. Use the 'Add to project'->'Import YAML/JSON' menu item to import some files to your catalog. The easiest would be to open these files
in your browser and copy and paste their contents into the YAML/JSON text area.
.. the Entando EAP Quick Start image stream: https://raw.githubusercontent.com/entando/entando-ops/master/Openshift/image-streams/entando-eap71-quickstart-openshift.json
.. the Entando AppBuilder image stream: https://raw.githubusercontent.com/entando/entando-ops/master/Openshift/image-streams/appbuilder.json
.. the Entando EAP Quick Start template: https://raw.githubusercontent.com/entando/entando-ops/master/Openshift/templates/entando-eap71-quickstart.yml
. Go back to the Openshift landing page by clicking the 'OPENSHIFT' text in the top left corner
. Click on the 'Create Project' button in the top right area and type in the name 'entando-sample' for your new project
. Click on the link that displays the newly created project's name
. Click on the 'Browse Catalog' button
. Scroll until you find the template 'Entando in EAP 7.1'. (Sometimes there is a delay before this item shows up. If you cannot find it, delete your project, go drink some coffee, and then recreate your project again.)
. Click on the 'Entando in EAP 7.1' template, and follow the wizard. When you are prompted for parameter values, type the following parameter values:
.. Find out from your admins what the default domain suffix is for your Openshift cluster, usually something like
   'YOUR.CLUSTER.IP.nip.io'.
.. *Custom http Route Hostname for the Entando runtime and legacy screens*: type 'entando.YOUR.CLUSTER.IP.nip.io'. Your Entando app will be available at this domain name
.. *Context root of the Entando Runtime web app* should be set to "entando-sample" as this will be the context of the web app on the EAP server
.. If you have installed RedHat Process Automation Manager, you would require valid values for the following parameters:
... *KIE Server Base URL:*  the URL of the route that exposes the KIE Server, or any URL that can be used to access the KIE Server web application.
... *KIE Server Username:* The username that you configured for the KIE Server. This would be the value you provided for the 'KIE Server User' parameter
when installing  RedHat Process Automation Manager, or the value of the KIE_SERVER_USER environment variable on the KIE Server
deployment configuration in Openshift.
... *KIE Server Pasword:* The password that you configured for the KIE Server. This would be the value you provided for the 'KIE Server Password' parameter
when installing  RedHat Process Automation Manager, or the value of the KIE_SERVER_PWD environment variable on the KIE Server
deployment configuration in Openshift.
.. The default values would suffice for all the other parameters
. Navigate to the Builds->Builds menu item, confirm that a build has been triggered, and wait for this build to complete
. Once completed, navigate to Applications->Deployments and wait until you have two active deployments
. Once completed, navigate to Application->Routes
. To access the Entando App Builder, click on the URL for AppBuilder Route and log in using the following username/password: admin/adminadmin.
. To view the resulting Entando App, click on the URL for Entando 'runtime-http' Route and log in using the following admin/adminadmin.

.Steps using the `oc` command line interface:
. Log into your openshift cluster using `oc login -u USERNAME -p PASSWORD OPENSHIFT_CLUSTER_IP:8443` where
`OPENSHIFT_CLUSTER_IP` is the hostname or ip address of your Openshift cluster
. Set the current project to 'openshift': `oc project openshift`
. Install the following YAML and JSON files:
.. The Entando EAP image stream: `oc create -f https://raw.githubusercontent.com/entando/entando-ops/master/Openshift/image-streams/entando-eap71-quickstart-openshift.json`
.. The Entando AppBuilder image stream: `oc create -f https://raw.githubusercontent.com/entando/entando-ops/master/Openshift/image-streams/appbuilder.json`
.. The Quickstart template: `oc create -f https://raw.githubusercontent.com/entando/entando-ops/master/Openshift/templates/entando-eap71-quickstart.yml`
. Create an Openshift project for your Entando App: `oc new-project entando-sample`
. Deploy the template:
.. Determine what the default domain suffix is for your Openshift cluster, usually something like 'YOUR.CLUSTER.IP.nip.io'. Decide what domain name you
want your Entando instance to run on by specifying the *ENTANDO_RUNTIME_HOSTNAME_HTTP* parameter, e.g. ENTANDO_RUNTIME_HOSTNAME_HTTP=entando.YOUR.CLUSTER.IP.nip.io
.. The *ENTANDO_WEB_CONTEXT* paramater should be set to "entando-sample" as this will be the context of the web app on the EAP server
.. If you have installed RedHat Process Automation Manager, you would require valid values for the following parameters:
... *KIE_SERVER_BASE_URL*: the URL of the route that exposes the KIE Server
... *KIE_SERVER_USERNAME*: the username that you configured for the KIE Server. This would be the value you provided for the 'KIE Server User' parameter
when installling  RedHat Process Automation Manager, or the value of the KIE_SERVER_USER environment variable on the KIE Server
deployment configuration in Openshift.
... *KIE_SERVER_PASSWORD*: the password that you configured for the KIE Server. This would be the value you provided for the 'KIE Server Password' parameter
when installing  RedHat Process Automation Manager, or the value of the KIE_SERVER_PWD environment variable on the KIE Server
deployment configuration in Openshift.
.. Instantiating the template would then look something like this:

    oc process openshift//entando-eap-quickstart -p ENTANDO_RUNTIME_HOSTNAME_HTTP=entando.YOUR.CLUSTER.IP.nip.io
    -p ENTANDO_WEB_CONTEXT="entando-sample" -p KIE_SERVER_BASE_URL=kieserver.YOUR.CLUSTER.IP.nip.io -p KIE_SERVER_USERNAME=john_smith -p KIE_SERVER_PASSWORD=mypassword
    |oc create -f -

. Confirm that a build has been triggered by runnning: `oc get builds`. Wait for build to complete.
. Comfirm that two deployments have been triggered by running: `oc get dc`and then `oc get pods`. Wait until all pods are
in 'Running' status.
. List all the routes that were created using the command : `oc get routes`.
. To access the Entando App Builder, open its Route's URL in your browser and log in using the following username/password: admin/adminadmin.
. To view the resulting Entando App, open the 'runtime-http'  Route's URL in your browser log in using the following admin/adminadmin.

.Next steps

Now that you got started with Entando on Openshift, you may want to delve into the
process of managing the database yourself, or how to leverage Jenkins in Openshift
to setup your own pipeline, or how to promote your changes from one environment to the next.
For guidance on how to do this, please consult our <<entando-on-openshift>> section on
the use of our Openshift images and templates.

[[common-variables]]
== Common Variables on Docker
Once you have completed one of our <<getting-started>> tutorials, you should have one or more Docker containers running
either on Docker or on Openshift. Ultimately, that is what this chapter is about - taking a Docker image, configuring
the various variables required to successfully create a container from that image, and the creating and running the container.
Whether we do this from Docker Compose, the Fabric8 Docker Maven Plugin or from Openshift, at some point we have an
image to configure.

When configuring a Docker image for container creation, three different types of variables typically need to be provided
by the user:

.. The environment variables required by the image
.. The ports on the host that will be used to exposed the container's ports on
.. The volumes on the host that will be used to map the container's hard drive volumes on

In order to provide the correct values for these variables, the user needs to understand what the function of each
environment variable, image port and image volume is. We have kept these configuration variables
of our Entando Docker images as consistent as possible. The Entando images consistently associate the same functionality
with the same ports, volumes and environment variables. You can use this section as a reference on how to configure
the Entando images.

=== Environment Variables for images hosting the Entando database
.Applicable Images:
* {ENTANDO_POSTGRESQL95_BASE_IMAGE}
* {ENTANDO_POSTGRESQL95_OPENSHIFT_IMAGE}

.Environment Variables
** **PORTDB_DATABASE** - {PORTDB_DATABASE}
** **PORTDB_USERNAME** - {PORTDB_USERNAME}
** **PORTDB_PASSWORD** - {PORTDB_PASSWORD}
** **SERVDB_DATABASE** - {SERVDB_DATABASE}
** **SERVDB_USERNAME** - {SERVDB_USERNAME}
** **SERVDB_PASSWORD** - {SERVDB_PASSWORD}
** **ADMIN_USERNAME** - {ADMIN_USERNAME}
** **ADMIN_PASSWORD** - {ADMIN_PASSWORD}

=== Environment Variables for images hosting the Entando Engine
.Applicable Images

* {ENTANDO_EAP71_BASE_IMAGE}
* {ENTANDO_WILDFLY12_BASE_IMAGE}
* {ENTANDO_EAP71_QUICKSTART_OPENSHIFT_IMAGE}
* {ENTANDO_WILDFLY12_QUICKSTART_OPENSHIFT_IMAGE}
* {FSI_CC_DISPUTE_CUSTOMER_IMAGE}
* {FSI_CC_DISPUTE_ADMIN_IMAGE}
* {ENTANDO_ENGINE_API_IMAGE}


.Environment Variables
** **[[portdb_url]]PORTDB_URL** - {PORTDB_URL}
** **[[portdb_jndi]]PORTDB_JNDI** - {PORTDB_JNDI}
** **[[portdb_driver]]PORTDB_DRIVER** - {PORTDB_DRIVER}
** **[[portdb_username]]PORTDB_USERNAME** - {PORTDB_USERNAME}
** **[[portdb_password]]PORTDB_PASSWORD** - {PORTDB_PASSWORD}
** **[[portdb_service_host]]PORTDB_SERVICE_HOST** - {PORTDB_SERVICE_HOST}
** **[[portdb_service_port]]PORTDB_SERVICE_PORT** - {PORTDB_SERVICE_PORT}
** **[[servdb_url]]SERVDB_URL** - {SERVDB_URL}
** **[[servdb_jndi]]SERVDB_JNDI** - {SERVDB_JNDI}
** **[[servdb_driver]]SERVDB_DRIVER** - {SERVDB_DRIVER}
** **[[servdb_username]]SERVDB_USERNAME** - {SERVDB_USERNAME}
** **[[servdb_password]]SERVDB_PASSWORD** - {SERVDB_PASSWORD}
** **[[servdb_service_host]]SERVDB_SERVICE_HOST** - {SERVDB_SERVICE_HOST}
** **[[servdb_service_port]]SERVDB_SERVICE_PORT** - {SERVDB_SERVICE_PORT}
** **[[kie_server_base_url]]KIE_SERVER_BASE_URL** - {KIE_SERVER_BASE_URL}
** **[[kie_server_username]]KIE_SERVER_USERNAME** - {KIE_SERVER_USERNAME}
** **[[kie_server_password]]KIE_SERVER_PASSWORD** - {KIE_SERVER_PASSWORD}
** **[[entando_oidc_active]]ENTANDO_OIDC_ACTIVE** {ENTANDO_OIDC_ACTIVE}
** **[[entando_oidc_auth_location]]ENTANDO_OIDC_AUTH_LOCATION** - {ENTANDO_OIDC_AUTH_LOCATION}
** **[[entando_oidc_token_location]]ENTANDO_OIDC_TOKEN_LOCATION** - {ENTANDO_OIDC_TOKEN_LOCATION}
** **[[entando_oidc_client_id]]ENTANDO_OIDC_CLIENT_ID** - {ENTANDO_OIDC_CLIENT_ID}
** **[[entando_oidc_redirect_base_url]]ENTANDO_OIDC_REDIRECT_BASE_URL** - {ENTANDO_OIDC_REDIRECT_BASE_URL}



=== Environment Variables for images hosting the AppBuilder (and other JavaScript apps)
.Applicable Images
* {APP_BUILDER_IMAGE}

.Environment Variables
** **DOMAIN** - {DOMAIN}
** **CLIENT_SECRET** - {DOMAIN}

=== Common Ports

** **5000** - {PORT_5000}
** **8080** - {PORT_8080}
** **8778** - {PORT_8778}
** **8443** - {PORT_8443}
** **8443** - {PORT_8443}

[[common-volumes]]
=== Common Volumes
** **/entando-data** - contains the data that will be used and/or generated by the Entando app running in the container. In order to keep things simple, we generally map the following Maven
filter properties to subdirectories inside this volume:

*** **profile.resources.path=/entando-data/resources** - this is where uploaded files are stored
*** **profile.resources.path.protected=/entando-data/protected** - this is where sensitive files are stored such as database backups
*** **profile.index.path=/entando-data/indexdir** - this is where Entando builds its indices
*** **Embedded Derby Databases: /entando-data/databases** this contains the embedded Derby database for optional use, which can be ignored if you are pointing to a different database.

[[demos-on-docker]]
== Demos on Docker

Entando offers a couple of demos, such as the Entando Full Stack demo we had a look at in the <<getting-started>> section. In this section we will delve a bit deeper into
these demos on Docker and the various options they offer you.

[[entando-ful-stack-demo]]
=== Default Entando Full Stack demo
This demo was briefly discussed in the <<getting-started>> section. The entando Full Stack demo deploys two images. Follow their links to read more about the image in question

** {APP_BUILDER_IMAGE}
** {ENTANDO_ENGINE_API_IMAGE}

This demo exports the standard ports of 5000 and 8080 to the Docker host. On Linux this would be localhost, but on Windows and Apple it will be the IP address of the virtual machine
that hosts the Docker service.

The demo also allocates a local volume for the /entando-data volume. This volume contains the usual uploaded resources, protected and index files as described in the <<common-volumes>> section.
This particular configuration of the Entando Full Stack image comes with two pre-built embedded Derby databases that will be copied to the /entando-data/databases directory. Any changes
made to the underlying database will therefore be persisted in this volume and will thus survive container restarts, even when the container itself is removed.

To determine the location of the volume, first list the volumes using `docker volume ls` and then describe the
appropriate volume in more detail using `docker inspect entando-full-stack_entando-volume`. For Windows and Apple, keep in mind that those volumes are hosted inside the virtual machine
that hosts the Docker service. If you want to clear the volume, stop the Docker containers and run `docker volume rm entando-full-stack_entando-volume`. This will reset all data
stored in the volume.

=== Entando Full Stack on Postgresql

Wherease the default confguration of the Entando Full Stack image uses the two embeded Derby  databases, the configuration in
https://raw.githubusercontent.com/entando/entando-ops/credit-card-dispute/Docker/Production/entando-full-stack/docker-compose-postgresql.yml[docker-compose-postgresql.yml]
points Entando to an external database provided by our PostgreSQL. To run this demo, do the following:

.Steps:
. Download the Entando Full Stack docker-compose-postgresql.yml  file from https://github.com/entando/entando-ops/tree/credit-card-dispute/Docker/Production/entando-full-stack/docker-compose-postgresql.yml[Github]
. Open a terminal window and change the present working directory to the directory that you have downloaded the yaml file to.
. It is highly recommended that you first pull the required images from Docker Hub running the command `docker-compose -f docker-compose-postgresql.yml pull`
. Run the command `docker-compose -f docker-compose-postgresql.yml up` to spin up the required Docker containers
. Open your browser and point it to http://localhost:5000. This will open the AppBuilder. Note that on Apple or Windows you won't be using localhost but rather the IP address of the Docker virtual machine.
. Use the credentials admin/adminadmin to log in. Consult our documentation for more details on how to build an Entando App from AppBuilder
. To open the resulting web app, point your browser to http://localhost:8080/entando. Note that on Apple or Windows you won't be using localhost but rather the IP address of the Docker virtual machine.
. To access the PostgreSQL databases, point your database client to jdbc:postgresql://localhost:5432 and connect using postgres/adminpwd. (On Apple or Windows use the IP address of the Docker virtual machine.)

The key difference between this demo and the <<entando-ful-stack-demo>> is that the database here is hosted in a different container. For this reason, this demo requires
two Docker volumes:

. entando-volume.
. entando-pg-volume.

The first volume contains the usual uploaded resources, protected and index files as described in the <<common-volumes>> section, but no database.
The second volume contains the PostgreSQL database. If you want to reset the database, please delete this volume and let the PostgreSQL image recreate the database.

For more information on the individual images that this demo is composed of, follow these links:

** {APP_BUILDER_IMAGE}
** {ENTANDO_ENGINE_API_IMAGE}
** {ENTANDO_POSTGRESQL_IMAGE}

=== FSI Credit Card Dispute Demo

The Entando team, Red Hat and our business partners have collaborated to bring you a demo that illustrates how Entando can be used as the user experience layer for your
Red Hat Process Automation Manager processes. The process in question allows customers to initiate a dispute case against a specific transaction. This demo provides
two Entando apps - a customer facing app and a back-office app. These apps connect to a shared KIE Server instance.

.Steps:
. Download the Entando FSI Credit Card Dispuate Demo docker-compose.yml  file from https://github.com/entando/entando-ops/blob/credit-card-dispute/Docker/demos/docker-compose.yml[Github]
. Open a terminal window and change the present working directory to the directory that you have downloaded the yaml file to.
. It is highly recommended that you first pull the required images from Docker Hub running the command `docker-compose pull`
. Run the command `docker-compose up` to spin up the required Docker containers
. Open your browser and point it to http://localhost:5001. This will open the AppBuilder for the customer facing app.
. Use the credentials aryaStark/adminadmin to log in. Consult our documentation for more details on how to build an Entando App from AppBuilder
. Point your browser to http://localhost:5002. This will open the AppBuilder for the back-office app.
. Use the credentials admin/adminadmin to log in. Consult our documentation for more details on how to build an Entando App from AppBuilder
. To open the customer facing web app, point your browser to http://localhost:8081/fsi-credit-card-dispute-customer. Use aryaStark/adminadmin to log in
. To open the back-office web app, point your browser to http://localhost:8082/fsi-credit-card-dispute-backoffice. Use admin/adminadmin to log in

Both images in this demo come with their own embedded Derby databases. These databases are stored in the following Docker volumes

. entando-customer-volume
. entando-admin-volume

For more information about the images this demo is composed of, follow these links:

* {APP_BUILDER_IMAGE}
* {FSI_CC_DISPUTE_CUSTOMER_IMAGE}
* {FSI_CC_DISPUTE_ADMIN_IMAGE}

This demo is configured by default to use Entando's public Red Hat PAM environment, where the necessary rules, processes and model objects have been pre-installed.


== Designing your Entando pipeline.

Thus far we have only looked at Entando's pre-built demos. They illustrate what the end product could look like when deployed in the target environment.
However, none of these demos illustrate how your Entando App should be built, tested and promoted through your pipeline. As we start looking at Entando's Docker
support for Maven and Openshift, we will in fact start covering these topics. You will also be made aware of the different options that you have, and with this
you would need to be armed with the necessary knowledge to help you make the appropriate decision for your environment. In this section, we will take you through
a couple of significant issues to consider that will help you make these decisions.

=== Entando App Granularity

The scope and granularity of an Entando app play a significant role in designing the pipeline. By "scope", we need
to look specifically at the organisational scope of the app, that is who it is that needs to work on the app. If several people in your organisation work on an Entando
App, it is likely to be more coarse grained and your selected pipeline would look different compare to the pipeline of an Entando App that only has
one or two developers working on it. This section offers some guidelines to decide what the best pipeline approach would be for your specific use case

[[coarse-grained-apps]]
==== Coarse Grained Apps

A coarse grained Entando App typically involves a fairly complex site with a lot of content and a substantial database. In this case, you will find that
different authors with potentially different skill-sets contribute to the site concurrently. It is also very likely that some of your authors may not have
strong development skills and would not be comfortable addressing conflicts at a source code level. For this reason, you are likely to rely more on
Entando's CMS functionality to ensure that concurrent work against the site produces the expected result with minimum conflicts.

If this describes your usage of Entando, you would need a shared environment that everyone can work on concurrently. As such, the database backing
this shared environment is an extremely important asset to your organisation, and you need to take care in how you propogate the state of this database
from one environment to the next. We recommend that you leverage as much as possible of your existing database infrastructure and governance. For instance,
rather configure Entando to point to your existing database servers than using one of our database images inside the Openshift cluster. Entando doesn't currently
have any specific features that could simplify this for you, and we suggest  using a third party database migration tool such as Liquibase.
It is very important to ensure that the directory that you uploaded your content to is promoted exactly the same time as the database, and the responsibility
for this ultimately lies with your operations team.

In future releases of Entando we are hoping to provide more support for this use case. At this point in time, we do offer for a
https://access.redhat.com/containers/?tab=overview#/registry.connect.redhat.com/entando/entando-eap71-openshift-imagick[JBoss EAP Imagick image]. We have
pre-installed Imagick which is required for cropping and server side modification of uploaded images. Other than that, this image inherits the standard EAP
functionality from its https://access.redhat.com/containers/?tab=overview#/registry.access.redhat.com/jboss-eap-7/eap71-openshift[parent image]. You can
use this to build the appropriate configuration for your Entando app.

To summarize, this use case would typically involve the following steps:

. The Entando customer allocates the necessary space for the Entando database on their existing database infrastructure for DEV, STAGE and PROD environments.
. The Entando customer allocates the necessary space for uploaded files on network storage for DEV, STAGE and PROD environments.
. The Entando customer allocates the necessary resources for the Entando App on their Openshift cluster for all the environments. This app will be fairly large and needs explicit planning.
. The customer's developers prepare the appropriate selection of plugins for the Entando App in a maven project, and commits it to a  source control management tool such as Git
. The customer's developers may optionally customize Entando with additional plugins.
. The customer's developers and ops team configures a build pipeline for the Entando app on their existing Java and Maven infrastructure,
. At some point in the pipeline, a Docker image is built using the https://access.redhat.com/containers/?tab=overview#/registry.connect.redhat.com/entando/entando-eap71-openshift-imagick[JBoss EAP Imagick image]
. The source code of this Entando App will remain relatively static when compared to the database changes that will occur.
. The customer's content team does most of its work against one of the chosen shared environments, such as DEV or STAGE, but ideally not directly in PROD.
. When the necessary QA work is done, business decides to promote the app to the next environment.
. The customer's operations team then co-ordinates efforts to ensure the Database changes, the Docker image and the uploaded resources are deployed to the target environemt at exactly the same time.
. The customer's end users use the Entando App once it is promoted to production.

[[coarse-grained-apps]]
==== Fine Grained Apps

A fine grained Entando App typically involves a smaller, self-contained site. It would still involve some content and data, but not so much that you
need a fully fledged content management system to eliminate conflicts. If the authors have more advanced development skills, they would be
able to sort out all potential conflicts using the source control management tool of their choice. In this case, the database remains small and simple
enough for you to resolve all conflicts at the source code level, comparing the various SQL files that will populate the database in the target environment.
Most of our Docker and Openshift infrastructure supports this particular use case out of the box. The resources and files that make up the content of your site
would also be small enough that you can commit it to your source control management system without minimal overhead.

In this particular scenario, your database is not a very important asset - it can be restored from source code at any point in time. It can be considered to
be a fairly ephemeral piece of the puzzle, an as such, it would be much easier to provision your database in the Openshift cluster using one of our database images.
You wouldn't need to concern yourself with the synchronization of your uploaded content and your database, as both can be rebuilt from scratch every time you
deploy your Entando App to a given environment. In this scenario, it is therefore not necessary to tax your database administration and operations teams with the
details of database state propagation, and it would therefore be much lighter from a governance perspective.

This use case is significantly simpler to manage than <<coarse-grained-apps>>, but it comes at a cost. You need at least some development skills, and some knowledge
of source control management tools to contribute to such an app. For some scenarios, this may not be a price worth paying. You also need to actively manage the
complexity and scope of your apps, and make sure that a fine grained app never grows to such a size that it starts hogging your build and source control infrastructure.
But if you can nail these skills, the benefit is that you will benefit from most of the advantages that a typical microservices architecture offers.

To summarize, this use case would typically involve the following steps.
. The Entando customer would classify the planned Entando App in terms of size. (CPU consumption, memory, storage and database storage)
. The Entando customer's Openshift administration team would ensure that the necessary memory, storage and processing power is available to handle the required number of instances of this app.
. The customer's developers would setup a full CI/CD pipeline using whichever infrastructure is already in place for their other microservices.
. The customer's developers would implement all requirements using the `mvn jetty:run` command on a local machine.
. Once completed the developer would generate a database backup from Entando running in Jetty, and then commit the resulting SQL files.
. The developer would now resolve conflicts, and push the changes to the appropriate branch to trigger a build and test run in the appropriate environment, likely using ephemeral containers that were spun up just for these purposes.
. Once the automatic validation succeeds, the resulting Entando Image is tagged and deployed to a shared environment where non-technical people can verify its quality
. Once the QA has completed, the Entando App is tagged and deployed to Production for use by end users.

=== Your exisiting build infrastructure.

In our interactions with our customers, we have come to realize that it is difficult to make a generalization as to where all our customers are in their DevOps journey.
Some customers have already invested a lot of time and effort into establishing a more traditional centralized build server instance with minimal integration with Docker.
Other customers may have embraced Kubernetes and/or Openshift for all of their infrastructure. Some even have build, staging and production all included and hosted in
a single cluster whereas other have a set of interrelated clusters to do the job.  Still other customers may find themselves somewhere between having a centralized build
server and having a Kubernetes or Openshift cluster that hosts all the build infrastructure. For the purposes of designing your Entando pipeline, we will distinguish between
two different scenarios - a scenario where everything runs on Openshift, and a scenario where multiple divergent technologies are orchestrated to produce a Docker image
that will be deployed to Openshift (or any other Docker hosting environment for that matter).

[[pure-openshift-environment]]
====  Pure Openshift Environment
Opting for a pure Openshift environment for your entire pipeline offers some significant benefits. You can manage and scale your build infrastructure as easily as you
can manage and scale your deployment environments. You can scale out to a cloud provider if needed. You also have a centralized catalog of all pipeline related activity
that is happening and there is definitely a benefit in reusing your Openshift knowledge for your build environment. On the negative side, one has to acknowledge that
certain advanced build techniques that are not yet implemented in Openshift. It is also true that, whilst the Jenkins/Openshift integration already provides a viable
option, there are still some features that are not fully integrated, which results in duplication and/or overlap that can be quite difficult to navigate. All in all though,
this offers an appealing if perhaps slightly cutting edge option.

In a pure Openshift environment you are free to use the various build and deployment techniques described in its
https://docs.openshift.com/container-platform/3.9/dev_guide/application_lifecycle/promoting_applications.html[official documentation]. Entando has also implemented
a set of templates that would allow you to repeat and customize your configuration for various environments. If you want to take it one level further, we have a beta
version of our reference pipeline based on the https://www.oreilly.com/library/view/devops-with-openshift/9781491975954/ch04.html[DevOps with Openshift book].

In a pure Openshift environment we would recommend that you leverage the three types of BuildConfigs that Openshift offers to build your Docker images:
Source-to-Image builds, Dockerfile builds and Jenkins pipelines.

.. Source-to-Image builds certainly provide the simplest solution, and require almost no knowledge of Docker to get going. This facility simply
builds your Entando war file using Maven and leaves it to the S2I image to contribute it to the correct location in the image's file system. Entando does offer
https://github.com/entando/entando-ops/tree/credit-card-dispute/Openshift/s2i-images[several S2I images] to choose from, along with
https://github.com/entando/entando-ops/tree/credit-card-dispute/Openshift/templates[templates] that can facilitate the installation of these images.
.. The Dockerfile approach may be more appealing to those with strong Docker skills. Whereas we do use Dockerfile builds in our pipelines, Entando does not provide any
specific support for this approach other than offering several https://github.com/entando/entando-ops/tree/credit-card-dispute/Docker/base-images[base images] that you can choose from.
.. The Jenkins Pipeline approach is more powerful, but also comes with significant build overheads and a steep learning curve. The integration between Jenkins and Openshift
can be a bit finicky at times, and there is significant overlap and repetition that need to be addressed at a conceptual level. But once you have a Jenkins pipeline in place,
the increased flexibility and power does help significantly, especially in synchronizing Image deployment and database migration.

We will explore Entando's offering in this space in more detail in the <<entando-on-openshift>> section

[[hybrid-docker-environment]]
====  Hybrid Docker Environment
The hybrid Docker environment is very common amongst customers that are growing from a more traditional continuous integration approach to a full DevOps approach.
Such organizations often have mature continuous integration infrastructure from which it already benefits significantly. They may have evaluated Openshift's build
infrastructure but may have found it wanting on features that the organization already relies on, such as complex branch build algorithms required for pull requests.
It could also be that the organization simply has skills primarily in Bamboo and that the move to Jenkins doesn't seem like a cost effective step to take. Another
motivation here could be that the organization is not using Openshift on Docker in the deployment environment, but some other contaier orchestration product that
does not necessarily have Openshift's out-of-the-box support for builds. The end result though is the same: the organization uses existing continous integration
infrastructure for all build related activities, and Docker is reserved primarily for the the deployment environment.

In hybrid Docker environments, it is best to think of the Docker image as the unit of delivery that is handed off from the build environment to the Docker environment.
It almost serves the same role as tradition JEE war files did in the days of monolithic application servers. Like a JEE war file, the traditional build infrastructure
therefore produces and verifies the Docker image, and the publishes it to a shared artefact repository, in this case a Docker registry. During deployment to
a shared environment, the deployment process then picks up the Docker image and instantiates it with the correct environment variables in the target environment.

We would recommend using the Maven Docker plugin for these types of scenarios. It is a powerful build tool that allows you to produce the image immediately after
the Entando war file is built. It does however require that the Docker client is installed on the Bamboo agent or Jenkins slave, and that it is connected to a viable
Docker server. This can be a bit tricky when the agent/slave is a Docker container itself, but it is certainly doable. Once the image has been built and verified,
it can be handed off to any Docker based deployment environment. In fact, this makes the Maven Docker plugin very appealing for environments where the organization
does not want to be tied into a specific container orchestration vendor, such as Openshift or Cloud Foundry. We will look into this option in the <<maven-and-docker>>
section.

[[maven-and-docker]]
== Maven and Docker
In the <<maven-docker-quickstart>> section, we briefly looked at how to generate an Entando Maven project with the Maven Docker Plugin pre-configured. Once such
a project is in place, all one needs to do is run the following command and you have an Entando instance up and running:

`mvn clean install -Pdocker docker:start -DskipAppBuilderImage=false`

But happens behind the scenes here?

=== The pom.xml

Central to building and running a Docker image from your Entando Maven project is the configuration of several 'images' in the Docker Maven Plugin. The key
image configuration looks like this:

```
            <image>
              <name>entando/${project.artifactId}:${project.version}</name>
              <alias>${project.artifactId}</alias>
              <build>
                <skip>${skipEAPImage}</skip>
                <from>entando/entando-eap71-base:${entando.version}</from>
                <assembly>
                  <mode>dir</mode>
                  <targetDir>/opt/eap/standalone/deployments/</targetDir>
                  <descriptorRef>artifact</descriptorRef>
                </assembly>
              </build>
              <run>
                <skip>${skipEAPImage}</skip>
                <namingStrategy>alias</namingStrategy>
                <network>
                  <mode>custom</mode>
                  <name>${project.artifactId}-network</name>
                  <alias>${project.artifactId}</alias>
                </network>
                <dependsOn>
                  <!--Uncomment this if you want to use the PostgreSQL DB image -->
                  <!--<container>postgresql-${project.artifactId}</container> -->
                </dependsOn>
                <ports>
                  <port>8080:8080</port>
                </ports>
                <volumes>
                  <bind>
                    <volume>entando-docker-entando-data:/entando-data</volume>
                  </bind>
                </volumes>
                <!--Uncomment these if you want to use the PostgreSQL DB image -->
                <!--<env>-->
                  <!--<PORTDB_URL>jdbc:postgresql://postgresql-${project.artifactId}:5432/entandoPort</PORTDB_URL>-->
                  <!--<SERVDB_URL>jdbc:postgresql://postgresql-${project.artifactId}:5432/entandoServ</SERVDB_URL>-->
                  <!--<PORTDB_DRIVER>postgresql</PORTDB_DRIVER>-->
                  <!--<SERVDB_DRIVER>postgresql</SERVDB_DRIVER>-->
                <!--</env>-->
                <wait>
                  <log>Started [0-9]+ of [0-9]+ services</log>
                  <time>90000</time>
                </wait>
                <log>
                  <enabled>true</enabled>
                  <prefix>eap:</prefix>
                  <color>blue</color>
                </log>
              </run>
            </image>

```
Each image has a build configuration and a run configuration, both of which are activated or deactivated based on the `skipEAPImage`
system property. This pattern of activating specific images is used through the entire pom.xml. The build configuration of this specific image
element builds a new image from the `entando/entando-eap71-base:${entando.version}` image. It then takes the artifact produced by this
Maven project, a war file, and it contributes it to the resulting child image at the location /opt/eap/standalone/deployments.

The run configuration for this image then instantiates the image that was produced, exposes its port 8080 to port 8080 on the Docker host,
and mounts the entando-docker-entando-data volume at the location /entando-data. By default, it uses a pre-built embedded Derby
database, but the environment variables can be configured to point to an external database too.

There are similar image elements for the App Builder image and a PostgreSQL image. These are deactivated by default. There is also an example
of a slightly different configuration of Entando on a Wildfly 12 image. Please take some time to scan through these and note the various settings.

=== mvn jetty:run

Whereas it is entirely possible to use Maven to build and run the Entando Docker image, this flow of events still takes significantly longer than
simply running `mvn clean package jetty:run`. If you are looking for quick feedback to see what your Entando app looks like, we therefore recommend
that you still use the Maven Jetty plugin to do this. Once you have achieved the required results, it is then recommended that the developer verifies the resulting
Entando App at least once from the targeted Docker image. This will give the developer the confidence that the Image build will complete successfully on
the server and that all the integration points behave as expected. However, for the resulting app to behave as expected, its database needs to be in the
correct state.

=== Controlling the Database
One thing to keep in mind is that the default embedded database will not reflect any database changes nor restore any database backups that you have saved
in the project from `mvn jetty:run`. For this reason, we have also configured an intelligent PostgreSQL builder image that can host the Entando database,
the {ENTANDO_POSTGRESQL95_BASE_IMAGE}. Follow the link to read more about this image on its Github page.

There are two techniques that you can use to overcome this challenge:

==== Pointing the Jetty datasource to the PostgreSQL image
You could modify the src/main/filters/filter-development-unix.properties file to point to the PostgreSQL container configured from the pom.xml. This is probably
the easiest way to do things. You will notice that this image's run configuration exports the standard PostgreSQL port to port 5432 on the Docker host. You can
therefore connect to this server using a connection string such as `jdbc:postgresql://localhost:5432/entandoPort` in the appropriate filter properties file. To implement
this option, do the following:

. Change the following two properties in the appropriate filter properties file (filter-development-unix.properties  or filter-development-windows.properties depending on your operating system)

       profile.database.url.portdb=jdbc:postgresql://localhost:5432/entandoPort

       profile.database.url.servdb=jdbc:postgresql://localhost:5432/entandoServ

. Build and run the PostgreSQL image (but not the Entando EAP image) as follows:

       mvn clean package -Pdocker docker:start -DskipPostgreSQLImage=false -DskipEAPImage=true

. Start Jetty:

      mvn clean package jetty:run

. Make your modifications and verify them, and terminate the Jetty process once you are done.
. Uncomment the environment variables in your EAP image element to allow it to connect to the PostgreSQL container:

                <env>
                  <PORTDB_URL>jdbc:postgresql://postgresql-${project.artifactId}:5432/entandoPort</PORTDB_URL>
                  <SERVDB_URL>jdbc:postgresql://postgresql-${project.artifactId}:5432/entandoServ</SERVDB_URL>
                  <PORTDB_DRIVER>postgresql</PORTDB_DRIVER>
                  <SERVDB_DRIVER>postgresql</SERVDB_DRIVER>
                </env>

. Build and run the Entando App image as follows:

       mvn clean package -Pdocker docker:start

. Verify that it is behaving as expected at http://localhost:8080/entando-docker.


==== Rebuilding the PostgreSQL image
An alternative approach is to rebuild the PostgreSQL image every time you want to verify your changes from the Docker image. This option requires less configuration, but will
take a little longer to perform. To implement this option, do the following:

. Start Jetty:

      mvn clean package jetty:run

. Make your modifications and verify them
. Make database backup from the Entando admin web interface
. Terminate the Jetty process once you are done.
. Uncomment the environment variables in your EAP image element to allow it to connect to the PostgreSQL container:

                <env>
                  <PORTDB_URL>jdbc:postgresql://postgresql-${project.artifactId}:5432/entandoPort</PORTDB_URL>
                  <SERVDB_URL>jdbc:postgresql://postgresql-${project.artifactId}:5432/entandoServ</SERVDB_URL>
                  <PORTDB_DRIVER>postgresql</PORTDB_DRIVER>
                  <SERVDB_DRIVER>postgresql</SERVDB_DRIVER>
                </env>

. Now rebuild both the Entando EAP image and the PostgreSQL image

        mvn clean package -Pdocker docker:start -DskipPostgreSQLImage=false -DskipEAPImage=false

. Verify that it is behaving as expected at http://localhost:8080/entando-docker.

=== Volumes
In the pom.xml file, two Docker volumes have been configured:

          <volumes>
            <volume>
              <name>entando-docker-entando-data</name>
              <driver>local</driver>
            </volume>
            <volume>
              <name>entando-docker-entando-pg-data</name>
              <driver>local</driver>
            </volume>
          </volumes>

The `entando-docker-entando-data` volume is the standard entando-data volume that is mounted at /entando-data in the container once it has started. In this scenario, this
volume contains the indices that are generated. In the scenario where the default embedded Derby databases are used, those will also be stored here. if you need to
reset this data, run the following command to delete this volume:

     docker volume rm entando-docker-entando-data

The `entando-docker-entando-pg-data` volume is where the PostgreSQL database is stored. If you are using the PostgreSQL image, you can reset the database by running
the following commands:

     docker volume rm entando-docker-entando-pg-data

     mvn clean package -Pdocker docker:start -DskipPostgreSQLImage=false -DskipEAPImage=true

This will delete the existing database and allow the PostgreSQL image to build a new database based on the most recent backups.

=== Using different base images
In the default pom.xml generated from this Maven archetype, there is a choice of two different images that you can deploy your Entando WAR file to. The default choice
is the {ENTANDO_EAP71_BASE_IMAGE}.
Follow the link to read more about this image on its Github page.

     <from>entando/entando-eap71-base:${entando.version}</from>

You can turn this off by setting the `skipEAPImage` variable to true. Then you can activate the second option, the Entando Wildfly 12 base image by setting the
`skipWildflyImage` variable to false. This will activate the {ENTANDO_WILDFLY12_BASE_IMAGE}.
Follow the link to read more about this image on its Github page.

     <from>entando/entando-wildfly12-base:${entando.version}</from>

It is important to note that the war file produced by the Maven project is contributed to different locations depending on which image is chosen:
For Wildfly:

     <targetDir>/wildfly/standalone/deployments/</targetDir>

For EAP:

      <targetDir>/opt/eap/standalone/deployments/</targetDir>

One signficant limitation of these default base images is that they do not have Entando's clustered cache enable. This means that the Entandop Infinispan plugin will
not produce the expected performance enhancement. Entando currently only has an EAP base image available for these purposes. You can pull that image in by modifying the
`from` element from

     <from>entando/entando-eap71-base:${entando.version}</from>

to

     <from>entando/entando-eap71-clustered-base:${entando.version}</from>

This will activate {ENTANDO_EAP71_CLUSTERED_BASE_IMAGE}.
Follow the link to read more about this image on its Github page.

=== Docker Host IP Complexities
When integrating the Maven Docker Plugin into your existing build infrastructure, it may sometimes be challenging to figure out how to connect to the Docker server
that can perform the image build. The Maven Docker Plugin connects to the Docker host from a client process (Maven), and therefore may need to be told explicitly
where the Docker server is running. The `DOCKER_HOST` environment variable will allow you to specify the Docker server explicitly. There are a couple tips and tricks
to keep in mind in specifying the DOCKER_HOST variable:

. On most Docker distributions for Linux, it will be `localhost`. Your Linux configuration may also use a local unix socket /var/run/docker.sock
. If you are using the Docker service in Minishift or Minikube, the DOCKER_HOST should be the IP address of the Minishit/Minikube virtual machine.
. If you are using Docker on Windows or Apple, the DOCKER_HOST should be the IP address of the virtual machine that host the Docker server.
. If you are running your Maven build inside a Docker container, the gateway IP address 172.17.0.1 is almost always a safe bet for the DOCKER_HOST.

One more think to take note of is that, if you do have a `<wait>` element with an HTTP request url specified on your image run configuration, you need to use a correct Docker host as the
hostname segment of your URL. In fact, the same goes for any URL you use to access the exposed Docker port.

=== Verifying and Pushing your images
With the Docker image build and run now forming part of the Entando App's build process, it is fairly easy to do some automated testing against the resulting image.
You could use the Maven Failsafe plugin to initiate some integration tests after the container has started up successfully. This would allow you to performa some
verification before pushing the Image to the shared Docker registry.

The Maven Docker plugin also allows you to push the image to a shared Docker registry. It is highly recommended to use a secure registry for these purposes. You are
most likely to be pushing the image from a build server, in which case the recommended approach would be to define a `<server>` in the $HOME/.m2/settings.xml file. In
order for Maven to pick up the correct credentials, the `<id>` of the server element needs to be the same as the `hostname` segment in your Docker Image name. For example
if you have a Docker registry called `my.registry.com`, you need to specify your image as:

    <image>my.registry.com/somenamespace/myimage:1.0.4</image>

and your server configuration in the settings.xml file as

    <servers>
      <server>
        <id>my.registry.com</id>
        <username>myusername</username>
        <password>s!cr!t</password>
      </server>
      ....
    </servers>

Once all of this is in place, you can pushh all images in the Maven project using a single command:

    mvn -Pdocker docker:push


[[entando-on-openshift]]
== Entando on Openshift

Thus far in this chapter on containers, we have demonstrated how Entando's images can be used in a 'vanilla'
Docker deployment. We have also looked at how the Entando Docker base images can be used and extended using the
Fabric8 Maven Docker Plugin. None of these tools and techniques however are an solution for your running your
Docker containers in deployment just yet. For that, you would ultimately need a more mature container orchestration and
clustering product, such as Kubernetes, Openshift or Docker Swarm. At Entando we have focused our efforts
primarily on support for Openshift.

In this section, we will first get familiar with some of the core concepts in Openshift at the hand have a couple of
Entando's pre-built images. Then we'll exokire how to build your own images from the images and templates Entando offers.
This section will conclude with a look at how to setup Jenkins pipelines for Entando in Openshift

=== From Docker Compose to Openshift

In the section <<demos-on-docker>>, we used Docker Compose to install Entando's two pre-built demos. The pre-built
images were configured using the standard 'docker-compose.yml' files. Openshift Templates fulfill a very similar
role to docker-compose.yml files, and in fact can also be developed in the YAML format. Openshift Templates are
used to configure the following object that are used to build and deploy Docker images

.. At the heart of a typical Openshift Template would be one or more *DeploymentConfig* objects. We use these object
to configure how containers are created from images, and what Openshift should do with the containers environment
variables, ports and volumes. A DeploymentConfig can be configured to create multiple containers based on a single
image for clustering purposes.
.. One typically configures a *Service* object For each signficant port exposed by the containers produced by
a DeploymentConfig. Services are essential in the Kubernetes clustering and networking model. Each Service
has a cluster IP address that can be used to access the port that the Service is mapped to, but the load balancer
decides which container will serve each request.
.. *Routes* are used to assign externally accessible, user-friendly domain names and paths to specific services. Routes
are also used to configure HTTPS on Services that expose the HTTP protocol.
.. The *BuildConfig* complete the picture for those that want to host their entire pipeline in Openshift, as they allow you
to checkout source code and then perform some build operations on it with the goal of producing a new image.

Openshift Templates can be instantiated either from the commandline, or from the web-based Openshift Console. In the
section on the <<openshift-quickstart>>, we did in fact instantiate such a template, and we gave instructions on
how to do so either from the commandline or from the web console.

=== Entando Standard Openshift Template Parameters

When instantiating an Openshift Template, you also need to provide valid values for the Parameters in a Template.
These parameter values are often passed on directly to one of the DeploymentConfigs as environment variables to the
containers it manages. You will therefore often encounter one of Entando's standard image environment variable in the
form of an Openshift Template Parameter. There are also many Parameters in our templates that have exactly the same
function in each of the Templates they occur in. This is in line with our container design philosophy that we like
to keep things simple and consistent.

==== Parameters that map directly to Environment Variables
Please follow these links to the original environment variable for a full description of the environment variable
in question

* <<kie_server_base_url,KIE_SERVER_BASE_URL>> - {KIE_SERVER_BASE_URL}
* <<kie_server_username,KIE_SERVER_USERNAME>> - {KIE_SERVER_USERNAME}
* <<kie_server_password,KIE_SERVER_PASSWORD>> - {KIE_SERVER_PASSWORD}
* <<entando_oidc_auth_location,ENTANDO_OIDC_AUTH_LOCATION>> - {ENTANDO_OIDC_AUTH_LOCATION}
* <<entando_oidc_token_location,ENTANDO_OIDC_TOKEN_LOCATION>> - {ENTANDO_OIDC_TOKEN_LOCATION}
* <<entando_oidc_client_id,ENTANDO_OIDC_CLIENT_ID>> - {ENTANDO_OIDC_CLIENT_ID}
* <<entando_oidc_redirect_base_url,ENTANDO_OIDC_REDIRECT_BASE_URL>> - {ENTANDO_OIDC_REDIRECT_BASE_URL}

==== Standard Parameters in Entando Openshift Templates

* *[[application_name]]APPLICATION_NAME* - {APPLICATION_NAME}
* *[[image_stream_namespace]]IMAGE_STREAM_NAMESPACE* - {IMAGE_STREAM_NAMESPACE}
* *[[image_stream_tag]]IMAGE_STREAM_TAG* - {IMAGE_STREAM_TAG}
* *[[entando_runtime_hostname_http]]ENTANDO_RUNTIME_HOSTNAME_HTTP(S)* - {ENTANDO_RUNTIME_HOSTNAME_HTTP}
* *[[entando_app_builder_hostname_http]]ENTANDO_APP_BUILDER_HOSTNAME_HTTP(S)* - {ENTANDO_APP_BUILDER_HOSTNAME_HTTP}
* *[[entando_web_context]]ENTANDO_WEB_CONTEXT* - {ENTANDO_WEB_CONTEXT}
* *[[source_repository_url]]SOURCE_REPOSITORY_URL* - {SOURCE_REPOSITORY_URL}
* *[[source_repository_ref]]SOURCE_REPOSITORY_REF* - {SOURCE_REPOSITORY_REF}
* *[[source_secret]]SOURCE_SECRET* - {SOURCE_SECRET}
* *[[context_dir]]CONTEXT_DIR* - {CONTEXT_DIR}
* *[[volume_capacity]]VOLUME_CAPACITY* - {VOLUME_CAPACITY}
* *[[memory_limit]]MEMORY_LIMIT* - {MEMORY_LIMIT}

=== Deploying the Entando pre-built images

Entando's two pre-built demos can be deployed to Openshift using one of our Templates built for these purposes. Refer
back to the <<openshift-quickstart>> on more detailed instructions on how to instantiate a Template. In this section
we will focus primarily on the Parameters of the Template in question, and how the images are configured inside the
Template' BuildConfigs. Remember to install the prerequisite ImageStreams in the Openshift project you have decided
to use for these purposes.

==== Full Stack Template
The Entando Full Stack Template installs an Entando App that contains all of the standard Entando plugins.

.Images used
* {APP_BUILDER_IMAGE}
* {ENTANDO_ENGINE_API_IMAGE}

.Prerequisite Image Streams
* {APP_BUILDER_IMAGE_STREAM}
* The Entando Full Stack Image stream: https://raw.githubusercontent.com/entando/entando-ops/master/Openshift/image-streams/entando-sample-full.json

.Parameters
* *DOMAIN_SUFFIX*  - {DOMAIN_SUFFIX}
* *<<image_stream_tag,IMAGE_STREAM_TAG>>* - {IMAGE_STREAM_TAG}
* *<<image_stream_namespace,IMAGE_STREAM_NAMESPACE>>* - {IMAGE_STREAM_NAMESPACE}
* *<<kie_server_baseurl,KIE_SERVER_BASE_URL>>* - {KIE_SERVER_BASE_URL}
* *<<kie_server_username, KIE_SERVER_USERNAME>>* - {KIE_SERVER_USERNAME}
* *<<kie_server_password, KIE_SERVER_PASSWORD>>* - {KIE_SERVER_PASSWORD}
* *<<volume_capacity, VOLUME_CAPACITY>>* - {VOLUME_CAPACITY}

.Example Installation Script
https://github.com/entando/entando-ops/blob/credit-card-dispute/Openshift/installers/install-entando-full-stack.sh

.Important URLS

NB!! Replace $DOMAIN_SUFFIX with the value you used for the DOMAIN_SUFFIX parameter mentioned earlier. Use the
standard admin username/password combination admin/adminadmin to log into both URLs.

* The Full Stack Entando app: http://entando-full-stack.$DOMAIN_SUFFIX/entando
* AppBuilder: http://entando-full-stack-appbuilder.$DOMAIN_SUFFIX

.Persistent Volume Claims

* *entando-full-stack-claim* - Contains the two embedded Derby databases by default. Will also contain any uploaded
  files, database backups and indices generated by Entando

==== FSI Template
The Entando FSI Credit Card Dispute demo illustrates how Entando can be used as the presentation tier for
Red Hat PAM Case Management. It comes with two pre-built Docker images, each containing an Entando App that is served
from JBoss EAP. The

.Images used
* {APP_BUILDER_IMAGE}
* {FSI_CC_DISPUTE_CUSTOMER_IMAGE}
* {FSI_CC_DISPUTE_ADMIN_IMAGE}

.Prerequisite Image Streams
* {APP_BUILDER_IMAGE_STREAM}
* The Entando FSI Credit Card Dispute Image Streams: https://raw.githubusercontent.com/entando/entando-ops/master/Openshift/image-streams/entando-fsi-ccd-demo.json

.Parameters
* *DOMAIN_SUFFIX*  - {DOMAIN_SUFFIX}
* *<<image_stream_tag,IMAGE_STREAM_TAG>>* - {IMAGE_STREAM_TAG}
* *<<image_stream_namespace,IMAGE_STREAM_NAMESPACE>>* - {IMAGE_STREAM_NAMESPACE}
* *<<kie_server_baseurl,KIE_SERVER_BASE_URL>>* - {KIE_SERVER_BASE_URL}
* *<<kie_server_username, KIE_SERVER_USERNAME>>* - {KIE_SERVER_USERNAME}
* *<<kie_server_password, KIE_SERVER_PASSWORD>>* -{KIE_SERVER_PASSWORD}
* *<<volume_capacity, VOLUME_CAPACITY>>* - {VOLUME_CAPACITY}

.Example Installation Script
https://github.com/entando/entando-ops/blob/credit-card-dispute/Openshift/installers/install-fsi-ccd-demo.sh

.Important URLS

NB!! Replace $DOMAIN_SUFFIX with the value you used for the DOMAIN_SUFFIX parameter mentioned earlier. Use the
standard admin username/password combination admin/adminadmin to log into both URLs.

* The Entando Customer App: http://ccd-customer.$DOMAIN_SUFFIX/fsi-credit-card-dispute-customer
* AppBuilder for the Customer App: http://ccd-customer-appbuilder.$DOMAIN_SUFFIX
* The Entando Back Office App: http://ccd-admin.$DOMAIN_SUFFIX/fsi-credit-card-dispute-backoffice
* AppBuilder for the Back Office App: http://ccd-admin-appbuilder.$DOMAIN_SUFFIX


.Persistent Volume Claims

* *ccd-customer-entando-claim* Contains the two embedded Derby databases for the Customer App
* *ccd-admin-entando-claim* Contains the two embedded Derby databases for the Back Office App

=== Building your own Entando images

The first couple of Openshift examples illustrate how the end product of an Entando App can be deployed on Openshift in
the form of pre-built images. However, Openshift also allows for the images to be built on the Openshift platform itself.
In this section we will have a closer look at some of the Templates and S2I builder images that can be used to package
and deploy your Entand App Image


==== Quickstart Template

We looked briefly at the Entando <<openshift-quickstart>> Template in an earlier section in this chapter. This section
will explore the Quickstart template in a bit more detail.

.Images used
* {APP_BUILDER_IMAGE}
* {ENTANDO_EAP71_QUICKSTART_OPENSHIFT_IMAGE}

.Prerequisite Image Streams
* {APP_BUILDER_IMAGE_STREAM}
* {ENTANDO_EAP71_QUICKSTART_OPENSHIFT_IMAGE_STREAM}

.Parameters
* *APPLICATION_NAME* - {APPLICATION_NAME}
* *IMAGE_STREAM_TAG* - {IMAGE_STREAM_TAG}
* *ENTANDO_APP_BUILDER_HOSTNAME_HTTP* - {ENTANDO_APP_BUILDER_HOSTNAME_HTTP}
* *ENTANDO_RUNTIME_HOSTNAME_HTTP* - {ENTANDO_RUNTIME_HOSTNAME_HTTP} 
* *ENTANDO_WEB_CONTEXT* - {ENTANDO_WEB_CONTEXT}
* *KIE_SERVER_BASE_URL* - {KIE_SERVER_BASE_URL}
* *KIE_SERVER_USERNAME* - {KIE_SERVER_USERNAME}
* *KIE_SERVER_PASSWORD* - {KIE_SERVER_PASSWORD}
* *SOURCE_REPOSITORY_URL* - {SOURCE_REPOSITORY_URL}
* *SOURCE_REPOSITORY_REF* - {SOURCE_REPOSITORY_REF}
* *SOURCE_SECRET* - {SOURCE_SECRET}
* *CONTEXT_DIR* - {CONTEXT_DIR}
* *VOLUME_CAPACITY* {VOLUME_CAPACITY}
* *GITHUB_WEBHOOK_SECRET* - {GITHUB_WEBHOOK_SECRET}
* *GENERIC_WEBHOOK_SECRET* - {GENERIC_WEBHOOK_SECRET}
* *IMAGE_STREAM_NAMESPACE* - {IMAGE_STREAM_NAMESPACE}
* *MAVEN_MIRROR_URL* - {MAVEN_MIRROR_URL}
* *MAVEN_ARGS_APPEND* - {MAVEN_ARGS_APPEND}
* *ARTIFACT_DIR* - {ARTIFACT_DIR}
* *MEMORY_LIMIT* - {MEMORY_LIMIT}

.Example Installation Script
https://github.com/entando/entando-ops/blob/credit-card-dispute/Openshift/installers/install-entando-eap71-quickstart.sh

.Important URLS
The URLs you can access after the template was installed depends on the value of the relevant parameters you have provided
Use the standard admin username/password combination admin/adminadmin to log into both URLs.

* The Entando App: 'http://<<entando_runtime_hostname_http,$ENTANDO_RUNTIME_HOSTNAME_HTTP>>/<<entando_web_context,$ENTANDO_WEB_CONTEXT>>'
* AppBuilder: 'http://<<entando_app_builder_hostname_http,$ENTANDO_APP_BUILDER_HOSTNAME_HTTP>>/'


.Persistent Volume Claims

* *$APPLICATION_NAME-entando-claim* - contains the two embedded Derby databases for the Entando App, along wth files that
  will be uploaded, database backups and indices. (Replace $APPPLICATION_NAME with the value you provided for
  the APPLICATION_NAME parameter)

.Usage Notes
After installing the Entando EAP Quickstart Template, you will find two BuildConfigurations with following generated names:

* $APPLICATION_NAME-s2i-dbrebuild
* $APPLICATION_NAME-s2i-fast

The primary difference is that 'DB Rebuild' BuildConfig, as it name implies, rebuilds the database from scratch, and
restores any database backup that were store in the Maven project. If the database backup was created from Entando
running locally using `mvn jetty:run`, the database backup will be stored in the relative directory `src/main/webapp/protected`.
If this 'DB Rebuild' build detects a backup in that directory, it restores the database to that backup's state.
Unfortunately this database rebuild adds significantly to the build execution time. If you have not modified anying
in your database state, you can perform the "Fast" build, which only builds the war file.

It is quite important to keep track of what will be happening to the Persistent Volumne when a container is started from
an Image that has been built using the 'DB Rebuild' process. On startup, the container it first checks if the database
that it contains internally is newer than the database in the Persitent Volume. If so, it deletes the existing
databases from the Persistent Volume and copies the new ones across. After this, you are free to add content to the
database, but keep in mind that a 'DB Rebuild' could potentially destroy that content. It is therefore still
advisable to rather add content from an Entando instance that was started using `mvn jetty:run`.

Please note that this template is not intended for use in a production environment. The embedded Derby database is
not cluster safe. In a typical production environment, we would also recommend the use of our Infinispan plugin for
a cluster safe distributed cache. However, the {ENTANDO_EAP71_QUICKSTART_OPENSHIFT_IMAGE} used in this template
does not have JGroups configured on EAP to allow for a cluster safe cache.

==== PostgreSQL Template
WIP. Talk about selecting plugins, rebuild the database. Backup from tar files. Backup from sql files. Triggering builds
independently.

For production environments that do not require a shared CMS environment, we recommend the
entando-eap71-postgresql95-persistent template. This Template introduces a configuration for
JBoss EAP that has the clustered caches configured for Entando's Infinispan plugin. It also introduces a PostgreSQL 9.5
deployment with pre-configured connectivity from JBoss EAP to PostgreSQL.

.Images used
* {APP_BUILDER_IMAGE}
* {ENTANDO_EAP71_CLUSTERED_OPENSHIFT_IMAGE}
* {ENTANDO_POSTGRESQL95_OPENSHIFT_IMAGE}

.Prerequisite Image Streams
* {APP_BUILDER_IMAGE_STREAM}
* {ENTANDO_EAP71_CLUSTERED_OPENSHIFT_IMAGE_STREAM}
* {ENTANDO_POSTGRESQL95_OPENSHIFT_IMAGE_STREAM}

.Parameters
* *APPLICATION_NAME* - {APPLICATION_NAME}
* *IMAGE_STREAM_TAG* - {IMAGE_STREAM_TAG}
* *ENTANDO_APP_BUILDER_HOSTNAME_HTTP* - {ENTANDO_APP_BUILDER_HOSTNAME_HTTP}
* *ENTANDO_RUNTIME_HOSTNAME_HTTP* - {ENTANDO_RUNTIME_HOSTNAME_HTTP}
* *ENTANDO_BASEURL* - {ENTANDO_BASEURL}
* *SOURCE_REPOSITORY_URL* - {SOURCE_REPOSITORY_URL}
* *SOURCE_REPOSITORY_REF* - {SOURCE_REPOSITORY_REF}
* *SOURCE_SECRET* - {SOURCE_SECRET}
* *CONTEXT_DIR* - {CONTEXT_DIR}
* *ENTANDO_PORT_DATABASE* - {PORTDB_DATABASE}
* *ENTANDO_SERV_DATABASE* - {SERVDB_DATABASE}
* *DB_SECRET* - the Openshift secret containing the username and password to be used for the Entando user on PostgreSQL
* *ENTANDO_OIDC_ACTIVE* - {ENTANDO_OIDC_ACTIVE}
* *ENTANDO_OIDC_AUTH_LOCATION* - {ENTANDO_OIDC_AUTH_LOCATION}
* *ENTANDO_OIDC_TOKEN_LOCATION* - {ENTANDO_OIDC_TOKEN_LOCATION}
* *ENTANDO_OIDC_CLIENT_ID* - {ENTANDO_OIDC_CLIENT_ID}
* *ENTANDO_OIDC_REDIRECT_BASE_URL* - {ENTANDO_OIDC_REDIRECT_BASE_URL}
* *KIE_SERVER_SECRET* - the Openshift secret containing the 'username', 'password', 'url' that would provide access to a RedHat Process Automation Manager instance
* *VOLUME_CAPACITY* {VOLUME_CAPACITY}
* *HTTPS_SECRET*  - the name of the secret containing the keystore file
* *HTTPS_KEYSTORE* - the name of the keystore file within the secret
* *HTTPS_KEYSTORE_TYPE* -the type of the keystore file (JKS or JCEKS)
* *HTTPS_NAME* -the name associated with the server certificate
* *HTTPS_PASSWORD* - the password for the keystore and certificate
* *DB_MIN_POOL_SIZE* - sets xa-pool/min-pool-size for the configured datasource.
* *DB_MAX_POOL_SIZE* - sets xa-pool/max-pool-size for the configured datasource.
* *DB_TX_ISOLATION* - sets transaction-isolation for the configured datasource.
* *POSTGRESQL_MAX_CONNECTIONS* - the maximum number of client connections allowed. This also sets the maximum number of prepared transactions.
* *POSTGRESQL_SHARED_BUFFERS* - configures how much memory is dedicated to PostgreSQL for caching data.
* *GITHUB_WEBHOOK_SECRET* - {GITHUB_WEBHOOK_SECRET}
* *GENERIC_WEBHOOK_SECRET* - {GENERIC_WEBHOOK_SECRET}
* *IMAGE_STREAM_NAMESPACE* - {IMAGE_STREAM_NAMESPACE}
* *MAVEN_MIRROR_URL* - {MAVEN_MIRROR_URL}
* *MAVEN_ARGS_APPEND* - {MAVEN_ARGS_APPEND}
* *JGROUPS_ENCRYPT_SECRET* - the name of the secret containing the keystore file
* *JGROUPS_ENCRYPT_KEYSTORE* - the name of the keystore file within the secret
* *JGROUPS_ENCRYPT_NAME* - the name associated with the server certificate
* *JGROUPS_ENCRYPT_PASSWORD* - the password for the keystore and certificate
* *JGROUPS_CLUSTER_PASSWORD* -JGroups cluster password
* *ARTIFACT_DIR* - {ARTIFACT_DIR}
* *MEMORY_LIMIT* - {MEMORY_LIMIT}

.Example Installation Script
https://github.com/entando/entando-ops/blob/credit-card-dispute/Openshift/installers/install-entando-eap71-with-postgresql95.sh

.Important URLS
The URLs you can access after the template was installed depends on the value of the relevant parameters you have provided
Use the standard admin username/password combination admin/adminadmin to log into both URLs.

* The Entando App: the value of the ENTANDO_RUNTIME_HOSTNAME_HTTP parameter
* AppBuilder: the valule of the ENTANDO_APP_BUILDER_HOSTNAME_HTTP parameter


.Persistent Volume Claims

* *$APPLICATION_NAME-entando-claim* - the Persistent Volume where files  will be uploaded, database backups will be made and
   indices will be generated. (Replace $APPPLICATION_NAME with the value you provided for
  the APPLICATION_NAME parameter)
* *$APPLICATION_NAME-postgresql-claim* - the Persistent Volume where the PostgreSQL server will store all its databases.

.Usage Notes
After installing the Entando EAP Quickstart Template, you will find two BuildConfigurations with following generated names:

* *$APPLICATION_NAME-s2i* This is the standard EAP 7.1 S2I build that will generate a war file from the Maven project,
and contribute it to the resulting image at the location /opt/eap/standalone/deployments.
* *$APPLICATION_NAME-postgresql-s2i* This BuildConfig recreates a PostgreSQL database from the Maven project. It will
invoke all the necessary Entando plugins to ensure that the database schema reflects the current selection of Entando
plugins. If there is a database backup in the Maven project, it will restore that backup to the newly created database.
It there are any binary, 'tar' format backups, it will restore these backups. If you have been developing locally
on Entando using `mvn jetty:run`, you would need to run this build config every time you have changed the database which
you subsequently backed up.

Generating all the necessary keystores for this template can be quite a laborious task. Please work through our sample
installation script to see one approach of doing it. It is also perfectly acceptable not to use the HTTPS passthrouhg
Routes created by this Template, but instead create your own HTTPS edge Routes in Openshift.

==== Entando Imagick S2I Image
The Entando Imagick S2I Image is the only image that can be used safely for environments where you require a shared
CMS environment. The reason for this is that it has the Imagic image manipulation package installed in the Docker
Image. This package is required for uploaded images when it needs to be cropped or edited in other ways.

Currently you need to install this image manually, as the Template to install this image is still under development.

TODO creating a pull secret, creating app, expose. Create standalone.xml file, decide how you will be specificying
databases.


=== Jenkins Pipelines

==== Pure Openshift Pipeline
WIP discuss the Pipeline used for Entando Central

==== Example Hybrid Pipeline
WIP discuss a pipeline that will buidl an image outside of Openshift using Maven. Discuss how to push the image to the
share repository. (Create an example project like this)

